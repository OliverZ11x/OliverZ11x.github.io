# 无监督算法

聚类和降维
k-means和PCA
EM算法，k怎么确定

---

### k-means算法

K均值（K-means）聚类是一种常用的无监督聚类算法，其主要思想是将数据点分为K个簇，使得每个数据点都属于离它最近的簇的中心点所代表的簇。以下是K均值聚类的基本步骤：

1. **初始化**：随机选择K个数据点作为初始的簇中心。
2. **分配数据点**：对于每个数据点，根据其与各个簇中心的距离，将其分配到最近的簇中心所代表的簇。
3. **更新簇中心**：对每个簇，计算其所有数据点的均值，将该均值作为新的簇中心。
4. **重复步骤2和3**：迭代执行步骤2和3，直到簇中心不再发生显著变化或达到预定的迭代次数。

K均值聚类的优点包括简单易实现、计算效率高；缺点则包括对初始簇中心敏感，可能收敛到局部最优解，对离群点敏感等。在实际应用中，通常需要根据具体数据集的特点来选择适当的K值和优化算法参数。

### K-means聚类中K怎么确定？

确定K值是K均值聚类中的一个关键问题。一种常用的方法是使用肘部法则（elbow method）。肘部法则通过尝试不同的K值进行K均值聚类，并计算每个K值下的聚类误差（如SSE，簇内平方和），然后绘制K值与聚类误差的关系图。通常会发现随着K值的增加，聚类误差会逐渐减小，但在某个K值后，聚类误差的下降速度会急剧减缓，形成一个肘部。这个肘部对应的K值通常被认为是一个合适的选择。

另外，对于特定的应用领域，也可以借助领域知识或者实际需求来确定K值。例如，如果已经明确知道要分成的类别数量，那么K值就可以直接设定为该数量。

除了肘部法则，还有一些其他方法用来确定K值，如轮廓系数（silhouette score）和Gap统计量（Gap statistic），这些方法也可以作为参考。最终选择K值时，需要综合考虑具体数据集的特点和实际需求。

### k-meas算法有什么缺点？如何改进？

1. 对初始中心点敏感：K均值算法对初始中心点的选择很敏感，不同的初始中心点可能导致不同的聚类结果，甚至可能收敛到局部最优解。
2. 对异常值敏感：K均值算法对异常值敏感，异常值可能会影响簇中心的计算。
3. 处理不规则形状的簇困难：K均值算法假定簇是凸形的，对于非凸形状的簇，K均值算法的表现可能不佳。
4. 难以处理不同密度的簇：K均值算法难以处理不同密度的簇，因为它假定所有簇的密度相似。

K均值算法对初始值选取敏感的问题可以通过以下方式进行改进：

1. **多次随机初始化**：可以多次运行K均值算法，每次使用不同的随机初始化来获得不同的聚类结果，然后选择最优的结果。这样可以减少初始值选择的影响。
2. **K均值++算法**：K均值++算法是一种改进的初始化方法，它可以更好地选择初始簇中心，从而降低收敛到局部最优解的风险。
3. **谱聚类**：谱聚类是一种基于图论的聚类方法，它不需要显式地指定簇的数量，因此不需要初始值。谱聚类可以处理不规则形状的簇，并且对初始值不敏感。
 ^10a311
4. **密度聚类算法**：与K均值算法相比，密度聚类算法（如DBSCAN）对初始值的选择不太敏感，并且可以有效处理不同密度的簇以及噪声点。

---

# PCA？？？？

---

# 逻辑回归

损失函数

极大似然和逻辑回归有什么关系

GD2阶

# softmax

![](../%E6%B1%82%E8%81%8C%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/image/2024-06-02-20-39-57.png)

# 树模型

---

# 对于机器学习模型的理解

![](../%E6%B1%82%E8%81%8C%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/image/2024-06-02-19-05-13.png)

---

# 模型损失函数

回归和分类

### 回归

L2 loss(mse)

### 分类

logloss
cross-entropy loss
hinge loss

# 模型评估

### 评估方法

### 评估准则

---

